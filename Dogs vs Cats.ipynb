{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33039638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4e4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Width=128\n",
    "Image_Height=128\n",
    "Image_Size=(Image_Width,Image_Height)\n",
    "Image_Channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cecd4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=os.listdir(\"D:/dogs-vs-cats/train\")\n",
    "categories=[]\n",
    "for f_name in filenames:\n",
    "    category=f_name.split('.')[0]\n",
    "    if category=='dog':\n",
    "        categories.append(1)\n",
    "    else:\n",
    "        categories.append(0)\n",
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'category':categories\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aefd7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>dog.9995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>dog.9996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>dog.9997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>dog.9998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>dog.9999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  category\n",
       "0         cat.0.jpg         0\n",
       "1         cat.1.jpg         0\n",
       "2        cat.10.jpg         0\n",
       "3       cat.100.jpg         0\n",
       "4      cat.1000.jpg         0\n",
       "...             ...       ...\n",
       "24995  dog.9995.jpg         1\n",
       "24996  dog.9996.jpg         1\n",
       "24997  dog.9997.jpg         1\n",
       "24998  dog.9998.jpg         1\n",
       "24999  dog.9999.jpg         1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc225323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,\\\n",
    "     Dropout,Flatten,Dense,Activation,\\\n",
    "     BatchNormalization\n",
    "model=Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "  optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "908a69e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 12,942,786\n",
      "Trainable params: 12,941,314\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dce147a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop = EarlyStopping(patience = 10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',patience = 2,verbose = 1,factor = 0.5,min_lr = 0.00001)\n",
    "callbacks = [earlystop,learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0b77bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\n",
    "train_df,validate_df = train_test_split(df,test_size=0.20,\n",
    "  random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n",
    "total_train=train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "batch_size=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a146cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 5000 validated image filenames belonging to 2 classes.\n",
      "Found 0 validated image filenames belonging to 0 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jyoti\\.conda\\envs\\tensor flow\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:282: UserWarning: Found 20000 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1\n",
    "                                )\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"D:/dogs-vs-cats/train/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"D:/dogs-vs-cats/train/\", \n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=Image_Size,\n",
    "    class_mode='categorical',\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rotation_range=15,\n",
    "                                rescale=1./255,\n",
    "                                shear_range=0.1,\n",
    "                                zoom_range=0.2,\n",
    "                                horizontal_flip=True,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1)\n",
    "test_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                 \"D:/dogs-vs-cats/test/\",x_col='filename',y_col='category',\n",
    "                                                 target_size=Image_Size,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057067f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-f7b6d0c9c94b>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.7504 - accuracy: 0.6350WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 1475s 1s/step - loss: 0.7504 - accuracy: 0.6350 - val_loss: 0.5436 - val_accuracy: 0.7205\n",
      "Epoch 2/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.5473 - accuracy: 0.7300WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 779s 584ms/step - loss: 0.5473 - accuracy: 0.7300 - val_loss: 0.9966 - val_accuracy: 0.6240\n",
      "Epoch 3/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.7690WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 1035s 777ms/step - loss: 0.4950 - accuracy: 0.7690 - val_loss: 0.5650 - val_accuracy: 0.7622\n",
      "Epoch 4/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7844WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "1333/1333 [==============================] - 776s 582ms/step - loss: 0.4645 - accuracy: 0.7844 - val_loss: 0.4158 - val_accuracy: 0.8118\n",
      "Epoch 5/10\n",
      " 245/1333 [====>.........................] - ETA: 9:00 - loss: 0.4166 - accuracy: 0.8131"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec5ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1_catsVSdogs_10epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d17423",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Accuracy vs Val_Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61507a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = os.listdir(\"D:/dogs-vs-cats/test1\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc1d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = train_datagen.flow_from_dataframe(test_df,\n",
    "\"D:/dogs-vs-cats/test1/\",x_col='filename',y_col=None,\n",
    "target_size=Image_Size,\n",
    "class_mode=None,\n",
    "batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db8387",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85596e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)\n",
    "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
    "test_df['category'] = test_df['category'].replace(label_map)\n",
    "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3459646",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test = test_df.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    img = load_img(\"D:/dogs-vs-cats/test1/\"+filename, target_size=Image_Size)\n",
    "    plt.subplot(6, 3, index+1)\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93128969",
   "metadata": {},
   "outputs": [],
   "source": [
    "results={\n",
    "    0:'cat',\n",
    "    1:'dog'\n",
    "}\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open(\"D:/dogs-vs-cats/test1/180.jpg\")\n",
    "plt.imshow(im,cmap=plt.cm.binary)\n",
    "im=im.resize(Image_Size)\n",
    "im=np.expand_dims(im,axis=0)\n",
    "im=np.array(im)\n",
    "im=im/255\n",
    "pred=model.predict_classes([im])[0]\n",
    "\n",
    "print(pred,results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864e49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793a10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
